{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as pl\n",
    "import warnings\n",
    "# from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import display, HTML\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy<2\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\sohan\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sohan\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\sohan\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.14 requires opencv-contrib-python, which is not installed.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "torchvision 0.22.1 requires torch==2.7.1, but you have torch 2.6.0 which is incompatible.\n",
      "tsai 0.4.0 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\ProgramData\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (257235895.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    data = pd.read_csv(\"C:\\Users\\sohan\\Downloads\\Battery_RUL.csv\")\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\Users\\sohan\\Downloads\\Battery_RUL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(dataframe):\n",
    "    '''\n",
    "    A function that fetches all the Metadata Information about the Dataframe\n",
    "    This function can be reused for all Pandas Dataframe\n",
    "    '''\n",
    "    print(\"\\nBASIC INFORMATION\\n\")\n",
    "    print(dataframe.info())\n",
    "    print(\"=\" * 100)\n",
    "    print(\"STATISTICAL INFORMATION\")\n",
    "    display(dataframe.describe(include='all'))\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Dataframe Shape\\n\", dataframe.shape)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Number of Duplicate Rows\\n\", dataframe.duplicated().sum())\n",
    "    print(\"=\" * 100)\n",
    "    print(\"NULL Values Check\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metadata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('RUL, Remaining Useful Time Histogram')\n",
    "sns.histplot(data.RUL, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "sns.heatmap(data.corr(),annot=True, cbar=False, cmap='Blues', fmt='.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['Cycle_Index','Discharge Time (s)', 'Decrement 3.6-3.4V (s)', 'Time constant current (s)','Charging time (s)'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Max. Voltage Dischar. (V)'], data['RUL'], alpha=0.5)\n",
    "plt.title('Scatter Plot: Max. Voltage Discharge vs. Remaining Useful Lifetime')\n",
    "plt.xlabel('Max. Voltage Dischar. (V)')\n",
    "plt.ylabel('Remaining Useful Lifetime (RUL)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Min. Voltage Charg. (V)'], data['RUL'], alpha=0.5)\n",
    "plt.title('Scatter Plot: Min. Voltage Charge vs. Remaining Useful Lifetime')\n",
    "plt.xlabel('Min. Voltage Charg. (V)')\n",
    "plt.ylabel('Remaining Useful Lifetime (RUL)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Time at 4.15V (s)'], data['RUL'], alpha=0.5)\n",
    "plt.title('Scatter Plot: Time at 4.15V vs. Remaining Useful Lifetime')\n",
    "plt.xlabel('Time at 4.15V (s)')\n",
    "plt.ylabel('Remaining Useful Lifetime (RUL)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.147512,
     "end_time": "2023-12-27T22:23:22.648615",
     "exception": false,
     "start_time": "2023-12-27T22:23:22.501103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(['RUL'], axis=1)\n",
    "y = data['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.142473,
     "end_time": "2023-12-27T22:23:22.932444",
     "exception": false,
     "start_time": "2023-12-27T22:23:22.789971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2023, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.141987,
     "end_time": "2023-12-27T22:23:23.264850",
     "exception": false,
     "start_time": "2023-12-27T22:23:23.122863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, scalar):\n",
    "        self.scalar = scalar\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self.scalar.fit_transform(X)\n",
    "        return X, y\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        X = self.scalar.transform(X)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.138569,
     "end_time": "2023-12-27T22:23:23.533647",
     "exception": false,
     "start_time": "2023-12-27T22:23:23.395078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "robust = RobustScaler()\n",
    "pipeline = Pipeline(robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.146363,
     "end_time": "2023-12-27T22:23:23.808336",
     "exception": false,
     "start_time": "2023-12-27T22:23:23.661973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = pipeline.fit(X_train, y_train)\n",
    "X_test, y_test = pipeline.transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.129479,
     "end_time": "2023-12-27T22:23:24.065441",
     "exception": false,
     "start_time": "2023-12-27T22:23:23.935962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.168186,
     "end_time": "2023-12-27T22:23:24.363975",
     "exception": false,
     "start_time": "2023-12-27T22:23:24.195789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_regression.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = linear_regression.predict(X_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = linear_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_score = linear_regression.score(X_train, y_train)\n",
    "print(\"Score on Training Set: {:.2%}\".format(train_score))\n",
    "\n",
    "# Calculate and print the R^2 score on the test set\n",
    "test_score = linear_regression.score(X_test, y_test)\n",
    "print(\"Score on Test Set: {:.2%}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.130742,
     "end_time": "2023-12-27T22:23:24.676608",
     "exception": false,
     "start_time": "2023-12-27T22:23:24.545866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.202641,
     "end_time": "2023-12-27T22:23:25.010567",
     "exception": false,
     "start_time": "2023-12-27T22:23:24.807926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=3).fit(X_train,y_train)\n",
    "\n",
    "y_predictions = model.predict(X_test)# These are the predictions from the test data.\n",
    "\n",
    "print('training score: '+ \"{:.2%}\".format(model.score(X_train, y_train)))\n",
    "print('test score: '+ \"{:.2%}\".format(model.score(X_test,y_test)))\n",
    "print('Root Mean Squared Error: '+ \"{:.2f}\".format(mean_squared_error(y_test,y_predictions,squared=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.128017,
     "end_time": "2023-12-27T22:23:25.266483",
     "exception": false,
     "start_time": "2023-12-27T22:23:25.138466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 7.960081,
     "end_time": "2023-12-27T22:23:33.353339",
     "exception": false,
     "start_time": "2023-12-27T22:23:25.393258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_regressor = SVR(kernel='linear', C=1.0)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Evaluate the performance on the training set\n",
    "train_score = svm_regressor.score(X_train, y_train)\n",
    "print(\"Score on Training Set: {:.2%}\".format(train_score))\n",
    "\n",
    "# Calculate and print the R^2 score on the test set\n",
    "test_score = svm_regressor.score(X_test, y_test)\n",
    "print(\"Score on Test Set: {:.2%}\".format(test_score))\n",
    "\n",
    "# # Visualize the predicted vs actual values\n",
    "# plt.scatter(y_test, y_pred)\n",
    "# plt.xlabel('Actual Values')\n",
    "# plt.ylabel('Predicted Values')\n",
    "# plt.title('Actual vs Predicted Values for SVM Regression')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.129099,
     "end_time": "2023-12-27T22:23:33.609418",
     "exception": false,
     "start_time": "2023-12-27T22:23:33.480319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.849089,
     "end_time": "2023-12-27T22:23:37.585326",
     "exception": false,
     "start_time": "2023-12-27T22:23:33.736237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a decision tree regressor model\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model1 = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model1.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error on Test Set: \", mse)\n",
    "\n",
    "train_score = best_model1.score(X_train, y_train)\n",
    "print(\"Score on Training Set: {:.2%}\".format(train_score))\n",
    "\n",
    "# Calculate and print the R^2 score on the test set\n",
    "test_score = best_model1.score(X_test, y_test)\n",
    "print(\"Score on Test Set: {:.2%}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.132901,
     "end_time": "2023-12-27T22:25:58.910397",
     "exception": false,
     "start_time": "2023-12-27T22:25:58.777496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 745.378037,
     "end_time": "2023-12-27T22:38:24.420567",
     "exception": false,
     "start_time": "2023-12-27T22:25:59.042530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, scoring='r2', cv=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by the grid search\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Calculate and print the R^2 score on the training set\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "print(\"R^2 Score on Training Set: {:.2%}\".format(train_score))\n",
    "\n",
    "# Calculate and print the R^2 score on the test set\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"R^2 Score on Test Set: {:.2%}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.132696,
     "end_time": "2023-12-27T22:38:24.687102",
     "exception": false,
     "start_time": "2023-12-27T22:38:24.554406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 55.141675,
     "end_time": "2023-12-27T22:39:19.963186",
     "exception": false,
     "start_time": "2023-12-27T22:38:24.821511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_model(X, y):\n",
    "    algorithms = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Decision Tree': DecisionTreeRegressor(),\n",
    "        'Random Forest': RandomForestRegressor(),\n",
    "        'Support Vector Machine': make_pipeline(RobustScaler(), SVR())\n",
    "        # Add more algorithms as needed\n",
    "    }\n",
    "\n",
    "    best_model_name = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    for name, model in algorithms.items():\n",
    "        # Using cross_val_score for simplicity\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='r2')  # You can change the scoring metric\n",
    "\n",
    "        # Take the mean of cross-validation scores as the performance metric\n",
    "        mean_score = scores.mean()\n",
    "\n",
    "        print(f\"{name} - R^2 Score: {mean_score:.4f}\")\n",
    "\n",
    "        # Update the best model if the current one has a higher score\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_model_name = name\n",
    "\n",
    "    print(f\"\\nBest Model: {best_model_name} with R^2 Score: {best_score:.4f}\")\n",
    "\n",
    "# Assuming X is your feature matrix and y is your target variable\n",
    "# Replace X and y with your actual feature matrix and target variable\n",
    "find_best_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
